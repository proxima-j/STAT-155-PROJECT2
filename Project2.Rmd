---
title: "Project2"
author: "Xiang Li, Jenny Li"
date: "2021/11/3"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load-packages, message = FALSE, echo=FALSE}
library(readr)
library(dplyr)
library(ggplot2)
library(ggmosaic)
library(broom)
library(knitr)
```

> Introduction to Topic

Sport, as an area receiving increased attention, responds as a result of increased awareness of people to their physical health, especially during the weird year 2020, where the pandemic changes the way of living as well as sport. Some sports benefit from it, some in alternative. Power lifting is a strength sport that consists of three attempts at maximal weight on three lifts: squat, bench press, and dead lift. At the same time, a perfect self-training exercise while staying at home during the pandemic. The central question of power lifting is how to lift successfully. This report contributes to discussing why someone successfully lifted as they expected while others didn’t use logistic regression.

> Research Questions

In order to find out why someone is more likely to lift while others don't, we decided to use the dataset that records the information of power lifting competitions over 22,000 meets and 412,000 lifters from competitors worldwide. Based on the massive amount of data, for accuracy and feasibility, we decided to narrow down our research question to: does a lifter's age and equipment impact the chance that they successfully lifted as expected? The response variable in this question contains a binary outcome, which would be narrowed down as the results in the category Squat1kg. The two explanatory variables are age and equipment. For the age class, we plan to focus on two specific age groups: "20-23" and "24-34". For equipment, we focus on the most popular equipment: "Raw" and "Single-ply". (Raw is categorized as equipment in the data, thus we continue it as equipment here.)

> Data 

> Context

In this report, we’ll use data from the OpenPowerlifting database as of April 2019. OpenPowerlifting is creating a public-domain archive of power lifting history. Power lifting is a sport in which competitors compete to lift the most weight for their class in three separate barbell lifts: the Squat, Bench, and Dead lift. The data is represented by openpowerlifting.csv, which includes all information on the meets (competitions) as well as the competitors who attended those meets worldwide. This dataset tracks 2554800 entries for 668172 lifters from 39909 meets. All the data in the dataset are collected by a team of about eight power lifters from official results posted on federations’ websites. Find more information about the dataset and download the openpowerlifting.csv file on Kaggle: https://www.kaggle.com/open-powerlifting/powerlifting-database. 

```{r load-data, message = FALSE}
# loading dataset
lifting <- read_csv (file = "openpowerlifting.csv")
```

> Cleaning

Since we are only focusing on the age class between "20-23" and "24-34" and equipment between "Raw" and "Single-ply", we filter the dataset left cases, in this particular dataset--participants, that fit either one of the age class while matching with either one of the equipment. In addition, since it is a binary outcome, we add a new variable called "LiftingSucess" which contains values of only 1 and 0, in which 1 refers to successful lifting while 0 refers to the failure of lifting based on the result of Squat1kg. Thus, after all the filtering, there are 120809 cases left in our dataset.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Count the number each age class
lifting %>%
    group_by(AgeClass) %>%
    summarise(Count = n())
# Filter data ageclass
lifting1<- lifting[!is.na(lifting$Squat1Kg), ] %>%
  filter(AgeClass %in% c("20-23", "24-34"))
# Count the number of each equipment
lifting1 %>%
    group_by(Equipment) %>%
    summarise(Count = n())
#filter the equipment
lifting1 <- lifting[!is.na(lifting$Squat1Kg), ] %>%
   filter(AgeClass %in% c("20-23", "24-34") & Equipment %in% c("Raw", "Single-ply") )
# define variable create liftingsuccess
lifting1 <- lifting1 %>%
  mutate(LiftingSuccess = ifelse(lifting1$Squat1Kg > 0, 1, 0))
```

> Logistic Regression

> Exploratory Data Analysis

When looking at the open power lifting before April 2019, our visualizations show us that the numbers of successful lifts seem similar in the two age classes. This could be explained due to the fact that although there are slightly more lifters in the age class of 24-34, the differences are balanced by the negative effect on the success rate when the age becomes larger. Such a situation could also be seen in Vis2, the second mosaic plot in which the bars of both age classes using single-ply are almost identical, but the bar of age class 24-34 is slightly wider than the bar of 20-23 with raw equipment. The Vis1 shows that lifters in age class 20-23 have a similar distribution of the probability of success with the age class 24-34, and it appears that more lifters are in raw equipment and have a higher successful lifting rate. Besides, our visualizations show us that lifters inferred to be raw equipment tend to achieve a successful lift across both age classes. According to the Vis2 shows that lifters in single-ply equipment are overall less likely to succeed (79.2% and 79.0% for age class 20-23 and 24-34 respectively) than in raw equipment (90.1% and 89.3% for males and females respectively).

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# create mosaic plot of liftingsuccess vs ageclass and equipment
lifting1 %>%
  ggplot() + 
  geom_mosaic(aes(x = product(LiftingSuccess, Equipment), fill = LiftingSuccess)) +
  facet_grid(. ~ AgeClass) +
  scale_fill_manual('Successfully Lifting? \n(1 = success, 0 = fail)', values = c('lightblue', 'steelblue')) + 
  labs(x = 'Inferred Binary Equipment', y = 'Successfully Lifting? (1 = yes, 0 = no)', title = "Vis1. Successfully Lifting vs Equipment and AgeClass")+
  theme_bw(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 12), 
        axis.text.x = element_text(hjust = 1, vjust = 1))
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# create mosaic plot of liftingsuccess vs ageclass and equipment
lifting1 %>%
  ggplot() + 
  geom_mosaic(aes(x = product(LiftingSuccess, AgeClass), fill = LiftingSuccess)) +
  facet_grid(. ~ Equipment) +
  scale_fill_manual('Successfully Lifting? \n(1 = success, 0 = fail)', values = c('lightblue', 'steelblue')) + 
  labs(x = 'Inferred Binary Equipment', y = 'Successfully Lifting? (1 = yes, 0 = no)', title = "Vis2. Successfully Lifting vs Equipment and AgeClass")+
  theme_bw(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 12), 
        axis.text.x = element_text(hjust = 1, vjust = 1))
```

> Model Creation

>Research Question: Are lifters in age class 20-23 more likely to success than the ageclass 24-34 in Squat1kg?

$$log(\widehat{Odds}[ Lifting Success = 1 | ageclass, equipment ] = \beta_0 + \beta_1 ageclass24-34 + \beta_2 equipmentSingleply $$
We consider that equipment would be a direct predictor of whether the lifter successfully lifted. At the same time, age class might be a confounder that is worth including since people of different age classes might prefer different equipment, and it might also directly affect the results. Other variables such as age, we consider redundant toward the age class, and the success rate of different lifting attempts is similar to the Squat 1kg. A logistic regression model is used to predict the categorical dependent variable with the help of independent variables. We fit this dataset in logistic regression because Lifting Success is a binary categorical outcome, which fits better in the logistic regression model.
As mentioned earlier, for accessibility, we only choose two variables that we are most interested in as the explanatory variables. Within the age class, we only choose the two that contain the most data to analyze and the equipment.

> Fitted Model

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# fit model and save as mod1
mod1 <- lifting1 %>%
   with(glm(LiftingSuccess ~ AgeClass + Equipment, family = binomial))
   print(mod1)
```

```{r get-coefficient-estimates-mod1, echo=FALSE, message=FALSE, warning=FALSE}
# print out tidy summary of mod1, focusing on estimates & exponentiated estimates
tidy(mod1, conf.int = TRUE) %>%
  mutate(estimate_exp = exp(estimate))
#exponentiated confidence interval for mod1
exp(confint(mod1))
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# creating table for fitted model
mytab <- as.table(cbind(c(8.860,0.9506,0.4395), c(0.01563986,0.01708027,0.01690717), c(8.5934,0.9193,0.4252), c(9.1368,0.9830,0.4543), c(0.0000,0.0030,0.0000)))
colnames(mytab) <- c("Estimate (exp)", "Standard Error", "Lower 95% CI", "Upper 95% CI", "P-value")
rownames(mytab) <- c("(Intercept)", " ageclass24-34", "equipmentSingle-ply")
kable(mytab)
```

> Model Interpretation

We estimate that the odds of successfully lifting for liters among those in the age class 20-23 and with raw equipment is 8.8601. We estimate that the odds of successfully lifting for lifters in the age class 24-34 are only 0.9506319 higher than the odds of successfully lifting for lifters in the age class 20-23 who used the same equipment. We estimate that the odds of successfully lifting for lifters in single-ply equipment are only 0.4395101 higher than the odds of successfully lifting for lifters in raw equipment in the same age class. These odds numbers show the relationship of lifting success rate with age class and the use of equipment is relatively weak. 

> Model Evaluation

```{r numerical-summaries, echo=FALSE, message=FALSE, warning=FALSE}
# corresponding numerical summaries for mod1
lifting1 %>%
  group_by(Equipment, AgeClass) %>%
  count(LiftingSuccess) %>%
  group_by(Equipment, AgeClass) %>%
  mutate(condprop = n/sum(n))
```

For the numerical summary, we look at the conditional proportion of lifters who did or did not successfully lift, given the lifter's inferred age class and equipment. It has shown a 90 percent chance that a lifter could successfully lift when falling into the category of 20-23 age class and with raw equipment, whereas when the lifter is in the age class of 24-34 and with raw equipment, the chance of successful lift will decrease to 89 percent. This is in line with the exponentiated beta 1 in the logistic model, the exponentiated coefficient of the age class variable, which is approaching 1, that although larger age might have a negative effect on the success rate of lift, it does not have a large impact on it. Moreover, if the lifter fell into the category of age class 20-23 and with Single-ply equipment, the chance of successful lift would be down to 79 percent. This also matches with the exponentiated beta 2 in the logistic regression, the exponentiated coefficient of the equipment variable, that applied single-ply as the equipment when lifting has a negative effect on the success rate, and it would have a relatively larger effect on it compared to the age class.

```{r predicted-probability-boxplots, echo=FALSE, message=FALSE, warning=FALSE}
# predicted probability boxplots for mod1
mod1 %>%
  augment(type.predict = 'response') %>% ## get predicted probabilities from model
  ggplot(aes(y = .fitted, x = factor(LiftingSuccess))) + ## compare predicted probabilites to actual outcome
  geom_boxplot() + 
  ylab('Predicted Probability of Successfully Lifting') + 
  xlab('Actual Outcome (1 = Success, 0 = Fail)') + 
  theme_classic() + 
  ggtitle('Predictions from Mod1')
```

For the graphical summaries, notice that our model tends to predict a slightly higher probability of success lift for lifters that did lift successfully than it does for lifters who did not: the predicted probability of success lift is above around 0.8 for most of the lifters(over 75%) that lifted successfully, and around 0.78 for most of the lifters that did not lift successfully. However, since overall they are very similar and there is so much overlap in the box plots, they suggest that our model can't classify or separate those who did lift successfully and who did not base just on their age class(particular for age class 20-23 and 24-34) and equipment(raw and single-ply). This is in line with the fact that the accuracy of the model is relatively not very high.

```{r model-quality-metrics, echo=FALSE, message=FALSE, warning=FALSE}
# get binary predictions for mod1
threshold <- 0.85
lift1 <- mod1 %>%
  augment(type.predict = 'response') %>% 
  mutate(predictSuccess = .fitted >= threshold) %>% 
  count(LiftingSuccess, predictSuccess) 
cat("Accuracy:", (lift1$n[1] + lift1$n[4])/(lift1$n[1] + lift1$n[4] + lift1$n[2] + lift1$n[3]), "\n")
cat("Sensitivity:", lift1$n[4]/(lift1$n[4] + lift1$n[3]), "\n")
cat("Specificity:", lift1$n[1]/(lift1$n[2] + lift1$n[1]), "\n")
cat("False negative:", lift1$n[3]/(lift1$n[3]+lift1$n[4]), "\n")
cat("False positive:", lift1$n[2]/(lift1$n[1]+lift1$n[2]), "\n")
```

Overall, the model has an accuracy of 0.6674 at predicting a lifter's lifting status correctly, predicting the lifter successfully lifting that actual success and predicting the lifter not successfully lifting that actually not success. The accuracy is 0.6674. In this case, the sensitivity is 0.6946, which means 0.6946 of them, the model predicted lifters successfully lifting that actual success. In this case, the specificity is  0.4990. The specificity is the proportion of the lifters who we predicted did not succeed that actually did not succeed. In addition, the false negative is 0.3054, which predicted did not successfully lift, but actually succeeded. This might be a disappointment for the lifters expecting a successful lift, but they didn't. On the other hand, the false positive is 0.5010, which predicted a successful lift, but actually not success. This might encourage the lifters to change to a higher lift or increase their confidence in lifting. Also, the logistic linear guaranteed to always get predictions between 0 and 1, which ensures the estimates' results are reasonable.

> Conclusion 

> General Takeaways

In summary, we could conclude that age and equipment do impact the success lift respectively. It has shown that if a lifter falls into the older age class, 24-34, it would be less likely to lift successfully than a lifter in the younger age group,20-23, holding other conduction constants. Moreover, if a lifter prefers to apply single-ply as the equipment, they would be less likely to lift successfully compared to others who prefer raw equipment in the same age class. However, the effect of age seems to be not significant, the chance of a lifter lifting successfully in both age classes with either equipment. The difference of equipment shows a relatively more explicit effect on the result, no matter which age class the lifter is in. Thus further research on the topic is needed.

> Limitations

This dataset was updated three years ago, which is a bit outdated. So, the data might not correctly represent the successful lifting rate impact by the age and equipment during recent times. We filter the data for only the lifters in age class 20-23 and 24-34 with raw or single-ply equipment, and we do not consider the other factors that may influence the outcome, such as sex and weight. The research question discusses how age and equipment will affect the rate of successfully lifting. We used age class instead of age, so the result might be just a broad relationship, which is not accurate enough in the age category. The sample is relatively small to answer the research question, and information bias could exist in age class. We only consider the successful lifting rate between the lifters in the age of 20-34. Thus, there might be a sampling bias in our data. 
Also, we only consider the success rate for one lifting attempt, which might not be the most accurate data to analyze. Another limitation might be that the logistic regression models are hard to interpret, including this one. Nevertheless, the potential benefits of such data might contribute to improving the training method of the lifters since they are eager to achieve a successful lift. Additionally, the database we are sampling from is originally selected from public resources. Therefore, it is possible to have a publicly available dataset.
However, due to the missing data, where the age class or equipment or both of a lifter has not been recorded, the model's accuracy is around 66 percent. Additionally, other variables, such as the weight of a lifter that might affect the outcome, have not been included in the model, which could decrease the model's accuracy. Therefore, we decided not to include an interaction term since it is reasonable to assume that age and equipment affect a successful lift separately.

> Appendix
> Works Cited

OpenPowerlifting. “Powerlifting Database.” Kaggle, April 25, 2019. https://www.kaggle.com/open-powerlifting/powerlifting-database.

> R Code

```{r,eval=FALSE}
library(readr)
library(dplyr)
library(ggplot2)
library(ggmosaic)
library(broom)
library(knitr)

# loding dataset
lifting <- read_csv (file = "openpowerlifting.csv")

# Count the number each age class
lifting %>%
    group_by(AgeClass) %>%
    summarise(Count = n())
# Filter data ageclass
lifting1<- lifting[!is.na(lifting$Squat1Kg), ] %>%
  filter(AgeClass %in% c("20-23", "24-34"))
# Count the number of each equipment
lifting1 %>%
    group_by(Equipment) %>%
    summarise(Count = n())
#filter the equipment
lifting1 <- lifting[!is.na(lifting$Squat1Kg), ] %>%
   filter(AgeClass %in% c("20-23", "24-34") & Equipment %in% c("Raw", "Single-ply") )
# define variable create liftingsuccess
lifting1 <- lifting1 %>%
  mutate(LiftingSuccess = ifelse(lifting1$Squat1Kg > 0, 1, 0))

# create mosaic plot of liftingsuccess vs ageclass and equipment
lifting1 %>%
  ggplot() + 
  geom_mosaic(aes(x = product(LiftingSuccess, Equipment), fill = LiftingSuccess)) +
  facet_grid(. ~ AgeClass) +
  scale_fill_manual('Successfully Lifting? \n(1 = success, 0 = fail)', values = c('lightblue', 'steelblue')) + 
  labs(x = 'Inferred Binary Equipment', y = 'Successfully Lifting? (1 = yes, 0 = no)', title = "Vis1. Successfully Lifting vs Equipment and AgeClass")+
  theme_bw(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 12), 
        axis.text.x = element_text(hjust = 1, vjust = 1))

# create mosaic plot of liftingsuccess vs ageclass and equipment
lifting1 %>%
  ggplot() + 
  geom_mosaic(aes(x = product(LiftingSuccess, AgeClass), fill = LiftingSuccess)) +
  facet_grid(. ~ Equipment) +
  scale_fill_manual('Successfully Lifting? \n(1 = success, 0 = fail)', values = c('lightblue', 'steelblue')) + 
  labs(x = 'Inferred Binary Equipment', y = 'Successfully Lifting? (1 = yes, 0 = no)', title = "Vis2. Successfully Lifting vs Equipment and AgeClass")+
  theme_bw(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 12), 
        axis.text.x = element_text(hjust = 1, vjust = 1))

# fit model and save as mod1
mod1 <- lifting1 %>%
   with(glm(LiftingSuccess ~ AgeClass + Equipment, family = binomial))
   print(mod1)
   
# print out tidy summary of mod1, focusing on estimates & exponentiated estimates
tidy(mod1, conf.int = TRUE) %>%
  mutate(estimate_exp = exp(estimate))
#exponentiated confidence interval for mod1
exp(confint(mod1))

# creating table for fitted model
mytab <- as.table(cbind(c(8.860,0.9506,0.4395), c(0.01563986,0.01708027,0.01690717), c(8.5934,0.9193,0.4252), c(9.1368,0.9830,0.4543), c(0.0000,0.0030,0.0000)))
colnames(mytab) <- c("Estimate (exp)", "Standard Error", "Lower 95% CI", "Upper 95% CI", "P-value")
rownames(mytab) <- c("(Intercept)", " ageclass24-34", "equipmentSingle-ply")
kable(mytab)

# corresponding numerical summaries for mod1
lifting1 %>%
  group_by(Equipment, AgeClass) %>%
  count(LiftingSuccess) %>%
  group_by(Equipment, AgeClass) %>%
  mutate(condprop = n/sum(n))

# predicted probability boxplots for mod1
mod1 %>%
  augment(type.predict = 'response') %>% ## get predicted probabilities from model
  ggplot(aes(y = .fitted, x = factor(LiftingSuccess))) + ## compare predicted probabilites to actual outcome
  geom_boxplot() + 
  ylab('Predicted Probability of Successfully Lifting') + 
  xlab('Actual Outcome (1 = Success, 0 = Fail)') + 
  theme_classic() + 
  ggtitle('Predictions from Mod1')

# get binary predictions for mod1
threshold <- 0.85
lift1 <- mod1 %>%
  augment(type.predict = 'response') %>% 
  mutate(predictSuccess = .fitted >= threshold) %>% 
  count(LiftingSuccess, predictSuccess) 
cat("Accuracy:", (lift1$n[1] + lift1$n[4])/(lift1$n[1] + lift1$n[4] + lift1$n[2] + lift1$n[3]), "\n")
cat("Sensitivity:", lift1$n[4]/(lift1$n[4] + lift1$n[3]), "\n")
cat("Specificity:", lift1$n[1]/(lift1$n[2] + lift1$n[1]), "\n")
cat("False negative:", lift1$n[3]/(lift1$n[3]+lift1$n[4]), "\n")
cat("False positive:", lift1$n[2]/(lift1$n[1]+lift1$n[2]), "\n")
```